{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Think Bayes\n",
    "\n",
    "Second Edition\n",
    "\n",
    "Copyright 2020 Allen B. Downey\n",
    "\n",
    "License: [Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)](https://creativecommons.org/licenses/by-nc-sa/4.0/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we're running on Colab, install empiricaldist\n",
    "# https://pypi.org/project/empiricaldist/\n",
    "\n",
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    !pip install empiricaldist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from empiricaldist import Pmf\n",
    "from utils import decorate, savefig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The train problem\n",
    "\n",
    "The train problem more hypothese than the dice problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypos = np.arange(1, 1001)\n",
    "prior = Pmf(1, hypos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the update function is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_train(pmf, data):\n",
    "    \"\"\"Update a pmf based on new data.\n",
    "    \n",
    "    pmf: Pmf of possible dice and their probabilities\n",
    "    data: integer train #\n",
    "    \"\"\"\n",
    "    hypos = pmf.qs\n",
    "    likelihood = 1 / hypos\n",
    "    impossible = (data > hypos)\n",
    "    likelihood[impossible] = 0\n",
    "    pmf *= likelihood\n",
    "    pmf.normalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But there are many more hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 60\n",
    "posterior = prior.copy()\n",
    "update_train(posterior, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what the posterior looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior.plot(label='Posterior after train 60')\n",
    "decorate(xlabel='Number of trains',\n",
    "         ylabel='PMF',\n",
    "         title='Train Problem')\n",
    "savefig('fig04-01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how we can compute the posterior mean\n",
    "\n",
    "$ \\mathrm{mean} = \\sum_i ~ p_i q_i $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(posterior.ps * posterior.qs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can use the method provided by `Pmf`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensitivity to the prior\n",
    "\n",
    "Here's a function that solves the train problem for different priors and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_train(pmf, dataset):\n",
    "    \"\"\"Solves the train problem.\n",
    "    \n",
    "    pmf: \n",
    "    dataset: sequence of observed train numbers\n",
    "    \n",
    "    returns: Pmf representing the posterior distribution\n",
    "    \"\"\"\n",
    "    for data in dataset:\n",
    "        pmf *= likelihood_train(data, hypos)\n",
    "\n",
    "    pmf.normalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run it with the same dataset and several uniform priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [30, 60, 90]\n",
    "\n",
    "for high in [500, 1000, 2000]:\n",
    "    hypos = np.arange(1, high+1)\n",
    "    pmf = Pmf(1, hypos)\n",
    "    for data in dataset:\n",
    "        update_train(pmf, data)\n",
    "    print(high, pmf.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are quite sensitive to the prior, even with several observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power law prior\n",
    "\n",
    "Now let's try it with a power law prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypos = np.arange(1, 1001)\n",
    "uniform = Pmf(1, hypos, name='uniform')\n",
    "uniform.normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1.0\n",
    "ps = hypos**(-alpha)\n",
    "power = Pmf(ps, hypos, name='power law')\n",
    "power.normalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what a power law prior looks like, compared to a uniform prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniform.plot()\n",
    "power.plot()\n",
    "\n",
    "decorate(xlabel='Number of trains',\n",
    "         ylabel='PMF',\n",
    "         title='Train Problem')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see what the posteriors look like after observing one train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [60]\n",
    "\n",
    "update_train(uniform, dataset)\n",
    "update_train(power, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniform.plot()\n",
    "power.plot()\n",
    "\n",
    "decorate(xlabel='Number of trains',\n",
    "         ylabel='PMF',\n",
    "         title='Train Problem')\n",
    "savefig('fig04-02')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The power law gives less prior probability to high values, which yields lower posterior means, and less sensitivity to the upper bound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1.0\n",
    "dataset = [30, 60, 90]\n",
    "\n",
    "for high in [500, 1000, 2000]:\n",
    "    hypos = np.arange(1, high+1)\n",
    "    ps = hypos**(-alpha)\n",
    "    power = Pmf(ps, hypos)\n",
    "    for data in dataset:\n",
    "        update_train(power, data)\n",
    "    print(high, power.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credible intervals\n",
    "\n",
    "To compute credible intervals, we can use the `credible_interval` method on the posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1.0\n",
    "dataset = [30, 60, 90]\n",
    "\n",
    "hypos = np.arange(1, 1001)\n",
    "ps = hypos**(-alpha)\n",
    "power = Pmf(ps, hypos)\n",
    "for data in dataset:\n",
    "    update_train(power, data)\n",
    "\n",
    "power.credible_interval(0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "power.lt_dist(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile(pmf, prob):\n",
    "    \"\"\"Compute a quantile.\n",
    "    \n",
    "    pmf: Pmf representing a normalized distribution\n",
    "    prob: float probability\n",
    "    \n",
    "    returns: quantity from the distribution\n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    for q, p in pmf.items():\n",
    "        total += p\n",
    "        if total >= prob:\n",
    "            return q\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, the median is 113."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile(power, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute the 5th and 95th percentiles, which make up a 90% confidence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile(power, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile(power, 0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Pmf` provides `quantile` which does the same thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "power.quantile([0.05, 0.95])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It also provides `credible_interval` which computes an interval that contains the given probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "power.credible_interval(0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Suppose you are giving a talk in a large lecture hall and you want to estimate the number of people in the audience.  There are too many to count, so you ask how many people were born on May 11 and two people raise their hands.  You ask how many were born on May 23 and 1 person raises their hand.  Finally, you ask how many were born on August 1, and no one raises their hand.\n",
    "\n",
    "How many people are in the audience?  What is the 90% credible interval for your estimate?\n",
    "\n",
    "Hint: Remember the binomial distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** I often see [rabbits](https://en.wikipedia.org/wiki/Eastern_cottontail) in the garden behind my house, but it's not easy to tell them apart, so I don't really know how many there are.\n",
    "\n",
    "Suppose I deploy a motion-sensing [camera trap](https://en.wikipedia.org/wiki/Camera_trap) that takes a picture of the first rabbit it sees each day.  After three days, I compare the pictures and conclude that two of them are the same rabbit and the other is different.\n",
    "\n",
    "How many rabbits visit my garden?\n",
    "\n",
    "To answer this question, we have to think about the prior distribution and the likelihood of the data:\n",
    "\n",
    "* I have sometimes seen four rabbits at the same time, so I know there are at least that many.  I would be surprised if there were more than 10.  So, at least as a starting place, I think a uniform prior from 4 to 10 is reasonable.\n",
    "\n",
    "* To keep things simple, let's assume that all rabbits who visit my garden are equally likely to be caught by the camera trap in a given day.  Let's also assume it is guaranteed that the camera trap gets a picture every day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Suppose that in the criminal justice system, all prison sentences are either 1, 2, or 3 years, with an equal number of each.  One day, you visit a prison and choose a prisoner at random.  What is the probability that they are serving a 3-year sentence?  What is the average remaining sentence of the prisoners you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** If I chose a random adult in the U.S., what is the probability that they have a sibling?  To be precise, what is the probability that their mother has had at least one other child.\n",
    "\n",
    "[This article from the Pew Research Center](https://www.pewsocialtrends.org/2015/05/07/family-size-among-mothers/) provides some relevant data.  From it, I extracted the following distribution of family size for mothers in the U.S. who were 40-44 years old in 2014:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs = [1, 2, 3, 4]\n",
    "ps = [22, 41, 24, 14]\n",
    "prior = Pmf(ps, qs)\n",
    "prior.bar(alpha=0.7)\n",
    "\n",
    "plt.xticks(qs, ['1 child', '2 children', '3 children', '4+ children'])\n",
    "decorate(ylabel='PMF',\n",
    "         title='Distribution of family size')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity, let's assume that all families in the 4+ category have exactly 4 children."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** The [Doomsday argument](https://en.wikipedia.org/wiki/Doomsday_argument) is \"a probabilistic argument that claims to predict the number of future members of the human species given an estimate of the total number of humans born so far.\"\n",
    "\n",
    "Suppose there are only two kinds of intelligent civilizations that can happen in the universe.  The \"short-lived\" kind go exinct after only 200 billion individuals are born.  The \"long-lived\" kind survive until 2,000 billion individuals are born.\n",
    "And suppose that the two kinds of civilization are equally likely.\n",
    "Which kind of civilization do you think we live in?  \n",
    "\n",
    "The Doomsday argument says we can use the total number of humans born so far as data.\n",
    "According to the [Population Reference Bureau](https://www.prb.org/howmanypeoplehaveeverlivedonearth/), the total number of people who have ever lived is about 108 billion.\n",
    "\n",
    "Since you were born quite recently, let's assume that you are, in fact, human being number 108 billion.\n",
    "If $N$ is the total number who will ever live and we consider you to be a randomly-chosen person, it is equally likely that you could have been person 1, or $N$, or any number in between.\n",
    "So what is the probability that you would be number 108 billion?\n",
    "\n",
    "Given this data and dubious prior, what is the probability that our civilization will be short-lived?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# According to this analysis, the probability is about 91% that our civilization will be short-lived.  \n",
    "# But this conclusion is based on a dubious prior.\n",
    "\n",
    "# And with so little data, the posterior depends strongly on the prior.  \n",
    "# To see that, run this analysis again with a different prior, and see what the results look like.\n",
    "\n",
    "# What do you think of the Doomsday argument?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
